#!/usr/bin/env python3
"""
VPPé¡¹ç›®ä»£ç è´¨é‡æ£€æŸ¥è„šæœ¬ v2.0
============================

å…¨é¢çš„ä»£ç è´¨é‡æ£€æŸ¥å·¥å…·ï¼ŒåŒ…æ‹¬ï¼š
- ä»£ç é£æ ¼æ£€æŸ¥
- å®‰å…¨æ¼æ´æ‰«æ
- æ€§èƒ½åˆ†æ
- ä¾èµ–å®‰å…¨æ£€æŸ¥
- æµ‹è¯•è¦†ç›–ç‡åˆ†æ
- æ–‡æ¡£å®Œæ•´æ€§æ£€æŸ¥

ä½¿ç”¨æ–¹æ³•:
    python scripts/quality_check.py --all
    python scripts/quality_check.py --security
    python scripts/quality_check.py --performance

ä½œè€…: VPP Development Team
ç‰ˆæœ¬: 2.0.0
æ›´æ–°: 2024-12-29
"""

import argparse
import json
import logging
import os
import subprocess
import sys
import time
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
import warnings

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('quality_check.log')
    ]
)
logger = logging.getLogger(__name__)

class QualityChecker:
    """ä»£ç è´¨é‡æ£€æŸ¥å™¨"""
    
    def __init__(self, project_root: str = "."):
        self.project_root = Path(project_root)
        self.results = {
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "checks": {},
            "summary": {
                "total_issues": 0,
                "critical_issues": 0,
                "warnings": 0,
                "score": 0
            }
        }
        
    def run_command(self, command: List[str], cwd: Optional[Path] = None) -> Tuple[int, str, str]:
        """è¿è¡Œå‘½ä»¤å¹¶è¿”å›ç»“æœ"""
        try:
            result = subprocess.run(
                command,
                cwd=cwd or self.project_root,
                capture_output=True,
                text=True,
                timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
            )
            return result.returncode, result.stdout, result.stderr
        except subprocess.TimeoutExpired:
            return -1, "", "Command timed out"
        except Exception as e:
            return -1, "", str(e)
    
    def check_python_style(self) -> Dict[str, Any]:
        """æ£€æŸ¥Pythonä»£ç é£æ ¼"""
        logger.info("ğŸ” æ£€æŸ¥Pythonä»£ç é£æ ¼...")
        
        results = {
            "black": {"status": "unknown", "issues": []},
            "isort": {"status": "unknown", "issues": []},
            "flake8": {"status": "unknown", "issues": []},
            "mypy": {"status": "unknown", "issues": []}
        }
        
        # Blackæ ¼å¼æ£€æŸ¥
        returncode, stdout, stderr = self.run_command([
            "black", "--check", "--diff", "."
        ])
        if returncode == 0:
            results["black"]["status"] = "passed"
        else:
            results["black"]["status"] = "failed"
            results["black"]["issues"] = stdout.split('\n') if stdout else []
        
        # isortæ£€æŸ¥
        returncode, stdout, stderr = self.run_command([
            "isort", "--check-only", "--diff", "."
        ])
        if returncode == 0:
            results["isort"]["status"] = "passed"
        else:
            results["isort"]["status"] = "failed"
            results["isort"]["issues"] = stdout.split('\n') if stdout else []
        
        # Flake8æ£€æŸ¥
        returncode, stdout, stderr = self.run_command([
            "flake8", ".", "--count", "--statistics", "--format=json"
        ])
        if returncode == 0:
            results["flake8"]["status"] = "passed"
        else:
            results["flake8"]["status"] = "failed"
            try:
                flake8_data = json.loads(stdout) if stdout else []
                results["flake8"]["issues"] = flake8_data
            except json.JSONDecodeError:
                results["flake8"]["issues"] = stdout.split('\n') if stdout else []
        
        # MyPyç±»å‹æ£€æŸ¥
        returncode, stdout, stderr = self.run_command([
            "mypy", ".", "--ignore-missing-imports", "--json-report", "/tmp/mypy_report"
        ])
        if returncode == 0:
            results["mypy"]["status"] = "passed"
        else:
            results["mypy"]["status"] = "failed"
            results["mypy"]["issues"] = stdout.split('\n') if stdout else []
        
        return results
    
    def check_security(self) -> Dict[str, Any]:
        """å®‰å…¨æ¼æ´æ£€æŸ¥"""
        logger.info("ğŸ›¡ï¸ è¿è¡Œå®‰å…¨æ£€æŸ¥...")
        
        results = {
            "bandit": {"status": "unknown", "issues": []},
            "safety": {"status": "unknown", "issues": []},
            "semgrep": {"status": "unknown", "issues": []}
        }
        
        # Banditå®‰å…¨æ£€æŸ¥
        returncode, stdout, stderr = self.run_command([
            "bandit", "-r", ".", "-x", "tests/", "-f", "json"
        ])
        
        if returncode == 0:
            results["bandit"]["status"] = "passed"
        else:
            results["bandit"]["status"] = "failed"
            try:
                bandit_data = json.loads(stdout) if stdout else {"results": []}
                results["bandit"]["issues"] = bandit_data.get("results", [])
            except json.JSONDecodeError:
                results["bandit"]["issues"] = [{"error": "Failed to parse bandit output"}]
        
        # Safetyä¾èµ–æ£€æŸ¥
        if (self.project_root / "requirements-lock.txt").exists():
            returncode, stdout, stderr = self.run_command([
                "safety", "check", "-r", "requirements-lock.txt", "--json"
            ])
            
            if returncode == 0:
                results["safety"]["status"] = "passed"
            else:
                results["safety"]["status"] = "failed"
                try:
                    safety_data = json.loads(stdout) if stdout else []
                    results["safety"]["issues"] = safety_data
                except json.JSONDecodeError:
                    results["safety"]["issues"] = [{"error": "Failed to parse safety output"}]
        
        return results
    
    def check_test_coverage(self) -> Dict[str, Any]:
        """æµ‹è¯•è¦†ç›–ç‡æ£€æŸ¥"""
        logger.info("ğŸ§ª æ£€æŸ¥æµ‹è¯•è¦†ç›–ç‡...")
        
        results = {
            "coverage": {"status": "unknown", "percentage": 0, "details": {}},
            "test_results": {"status": "unknown", "passed": 0, "failed": 0, "total": 0}
        }
        
        # è¿è¡Œæµ‹è¯•å¹¶ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
        returncode, stdout, stderr = self.run_command([
            "pytest", "tests/", "--cov=.", "--cov-report=json", "--cov-report=term", "-v"
        ])
        
        if returncode == 0:
            results["test_results"]["status"] = "passed"
        else:
            results["test_results"]["status"] = "failed"
        
        # è§£ææµ‹è¯•ç»“æœ
        test_lines = stdout.split('\n') if stdout else []
        for line in test_lines:
            if "passed" in line and "failed" in line:
                # è§£ææµ‹è¯•ç»Ÿè®¡ä¿¡æ¯
                pass
        
        # è¯»å–è¦†ç›–ç‡æŠ¥å‘Š
        coverage_file = self.project_root / "coverage.json"
        if coverage_file.exists():
            try:
                with open(coverage_file, 'r') as f:
                    coverage_data = json.load(f)
                    results["coverage"]["percentage"] = coverage_data.get("totals", {}).get("percent_covered", 0)
                    results["coverage"]["details"] = coverage_data.get("files", {})
                    results["coverage"]["status"] = "passed" if results["coverage"]["percentage"] >= 80 else "warning"
            except Exception as e:
                results["coverage"]["status"] = "error"
                results["coverage"]["error"] = str(e)
        
        return results
    
    def check_performance(self) -> Dict[str, Any]:
        """æ€§èƒ½æ£€æŸ¥"""
        logger.info("âš¡ è¿è¡Œæ€§èƒ½æ£€æŸ¥...")
        
        results = {
            "load_time": {"status": "unknown", "time_ms": 0},
            "memory_usage": {"status": "unknown", "peak_mb": 0},
            "benchmark": {"status": "unknown", "results": []}
        }
        
        # è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•
        if (self.project_root / "tests" / "test_performance.py").exists():
            returncode, stdout, stderr = self.run_command([
                "pytest", "tests/test_performance.py", "-v", "--benchmark-only"
            ])
            
            if returncode == 0:
                results["benchmark"]["status"] = "passed"
                results["benchmark"]["results"] = stdout.split('\n')
            else:
                results["benchmark"]["status"] = "failed"
                results["benchmark"]["error"] = stderr
        
        return results
    
    def check_documentation(self) -> Dict[str, Any]:
        """æ–‡æ¡£å®Œæ•´æ€§æ£€æŸ¥"""
        logger.info("ğŸ“š æ£€æŸ¥æ–‡æ¡£å®Œæ•´æ€§...")
        
        results = {
            "readme": {"exists": False, "quality": "unknown"},
            "api_docs": {"exists": False, "quality": "unknown"},
            "deployment_guide": {"exists": False, "quality": "unknown"},
            "docstrings": {"coverage": 0, "quality": "unknown"}
        }
        
        # æ£€æŸ¥READMEæ–‡ä»¶
        readme_files = ["README.md", "README.rst", "README.txt"]
        for readme in readme_files:
            if (self.project_root / readme).exists():
                results["readme"]["exists"] = True
                # ç®€å•çš„è´¨é‡æ£€æŸ¥
                with open(self.project_root / readme, 'r', encoding='utf-8') as f:
                    content = f.read()
                    if len(content) > 500:
                        results["readme"]["quality"] = "good"
                    else:
                        results["readme"]["quality"] = "basic"
                break
        
        # æ£€æŸ¥éƒ¨ç½²æŒ‡å—
        if (self.project_root / "DEPLOYMENT_GUIDE.md").exists():
            results["deployment_guide"]["exists"] = True
            results["deployment_guide"]["quality"] = "good"
        
        # æ£€æŸ¥APIæ–‡æ¡£
        api_doc_files = ["API.md", "api.md", "docs/API.md", "docs/api.md"]
        for api_doc in api_doc_files:
            if (self.project_root / api_doc).exists():
                results["api_docs"]["exists"] = True
                results["api_docs"]["quality"] = "good"
                break
        
        return results
    
    def check_dependencies(self) -> Dict[str, Any]:
        """ä¾èµ–æ£€æŸ¥"""
        logger.info("ğŸ“¦ æ£€æŸ¥é¡¹ç›®ä¾èµ–...")
        
        results = {
            "python_deps": {"status": "unknown", "locked": False, "outdated": []},
            "security_vulns": {"status": "unknown", "count": 0, "details": []}
        }
        
        # æ£€æŸ¥æ˜¯å¦æœ‰é”å®šçš„ä¾èµ–æ–‡ä»¶
        if (self.project_root / "requirements-lock.txt").exists():
            results["python_deps"]["locked"] = True
            results["python_deps"]["status"] = "good"
        elif (self.project_root / "requirements.txt").exists():
            results["python_deps"]["status"] = "warning"
            results["python_deps"]["message"] = "å»ºè®®ä½¿ç”¨é”å®šç‰ˆæœ¬çš„ä¾èµ–æ–‡ä»¶"
        
        return results
    
    def calculate_score(self) -> int:
        """è®¡ç®—ä»£ç è´¨é‡åˆ†æ•°"""
        score = 100
        
        # ä»£ç é£æ ¼æ‰£åˆ†
        style_checks = self.results["checks"].get("style", {})
        for tool, result in style_checks.items():
            if result["status"] == "failed":
                score -= 5
        
        # å®‰å…¨é—®é¢˜æ‰£åˆ†
        security_checks = self.results["checks"].get("security", {})
        for tool, result in security_checks.items():
            if result["status"] == "failed":
                issue_count = len(result.get("issues", []))
                score -= min(issue_count * 2, 20)  # æœ€å¤šæ‰£20åˆ†
        
        # æµ‹è¯•è¦†ç›–ç‡æ‰£åˆ†
        coverage = self.results["checks"].get("coverage", {}).get("coverage", {})
        if coverage.get("status") == "passed":
            coverage_pct = coverage.get("percentage", 0)
            if coverage_pct < 80:
                score -= (80 - coverage_pct) * 0.5
        
        # æ–‡æ¡£å®Œæ•´æ€§æ‰£åˆ†
        docs = self.results["checks"].get("documentation", {})
        if not docs.get("readme", {}).get("exists", False):
            score -= 5
        if not docs.get("deployment_guide", {}).get("exists", False):
            score -= 3
        
        return max(0, min(100, score))
    
    def generate_report(self) -> str:
        """ç”Ÿæˆè´¨é‡æŠ¥å‘Š"""
        score = self.calculate_score()
        self.results["summary"]["score"] = score
        
        report = []
        report.append("=" * 60)
        report.append("ğŸ¯ VPPé¡¹ç›®ä»£ç è´¨é‡æŠ¥å‘Š")
        report.append("=" * 60)
        report.append(f"ğŸ“Š ç»¼åˆå¾—åˆ†: {score}/100")
        report.append(f"ğŸ• æ£€æŸ¥æ—¶é—´: {self.results['timestamp']}")
        report.append("")
        
        # è¯¦ç»†ç»“æœ
        if "style" in self.results["checks"]:
            report.append("ğŸ“ ä»£ç é£æ ¼æ£€æŸ¥:")
            for tool, result in self.results["checks"]["style"].items():
                status_emoji = "âœ…" if result["status"] == "passed" else "âŒ"
                report.append(f"  {status_emoji} {tool}: {result['status']}")
            report.append("")
        
        if "security" in self.results["checks"]:
            report.append("ğŸ›¡ï¸ å®‰å…¨æ£€æŸ¥:")
            for tool, result in self.results["checks"]["security"].items():
                status_emoji = "âœ…" if result["status"] == "passed" else "âŒ"
                issue_count = len(result.get("issues", []))
                report.append(f"  {status_emoji} {tool}: {result['status']} ({issue_count} issues)")
            report.append("")
        
        if "coverage" in self.results["checks"]:
            coverage = self.results["checks"]["coverage"].get("coverage", {})
            coverage_pct = coverage.get("percentage", 0)
            status_emoji = "âœ…" if coverage_pct >= 80 else "âš ï¸"
            report.append(f"ğŸ§ª æµ‹è¯•è¦†ç›–ç‡: {status_emoji} {coverage_pct:.1f}%")
            report.append("")
        
        # æ”¹è¿›å»ºè®®
        report.append("ğŸ’¡ æ”¹è¿›å»ºè®®:")
        if score < 90:
            report.append("  â€¢ ä¿®å¤ä»£ç é£æ ¼é—®é¢˜")
        if score < 85:
            report.append("  â€¢ è§£å†³å®‰å…¨æ¼æ´")
        if score < 80:
            report.append("  â€¢ æé«˜æµ‹è¯•è¦†ç›–ç‡")
        if score < 75:
            report.append("  â€¢ å®Œå–„é¡¹ç›®æ–‡æ¡£")
        
        return "\n".join(report)
    
    def run_all_checks(self):
        """è¿è¡Œæ‰€æœ‰æ£€æŸ¥"""
        logger.info("ğŸš€ å¼€å§‹å…¨é¢è´¨é‡æ£€æŸ¥...")
        
        self.results["checks"]["style"] = self.check_python_style()
        self.results["checks"]["security"] = self.check_security()
        self.results["checks"]["coverage"] = self.check_test_coverage()
        self.results["checks"]["performance"] = self.check_performance()
        self.results["checks"]["documentation"] = self.check_documentation()
        self.results["checks"]["dependencies"] = self.check_dependencies()
        
        # ä¿å­˜è¯¦ç»†ç»“æœ
        with open("quality_report.json", "w") as f:
            json.dump(self.results, f, indent=2)
        
        # ç”Ÿæˆå¹¶æ˜¾ç¤ºæŠ¥å‘Š
        report = self.generate_report()
        print(report)
        
        # ä¿å­˜æŠ¥å‘Š
        with open("quality_report.txt", "w") as f:
            f.write(report)
        
        return self.results["summary"]["score"]


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="VPPé¡¹ç›®ä»£ç è´¨é‡æ£€æŸ¥å·¥å…·")
    parser.add_argument("--all", action="store_true", help="è¿è¡Œæ‰€æœ‰æ£€æŸ¥")
    parser.add_argument("--style", action="store_true", help="åªè¿è¡Œä»£ç é£æ ¼æ£€æŸ¥")
    parser.add_argument("--security", action="store_true", help="åªè¿è¡Œå®‰å…¨æ£€æŸ¥")
    parser.add_argument("--coverage", action="store_true", help="åªè¿è¡Œæµ‹è¯•è¦†ç›–ç‡æ£€æŸ¥")
    parser.add_argument("--performance", action="store_true", help="åªè¿è¡Œæ€§èƒ½æ£€æŸ¥")
    parser.add_argument("--docs", action="store_true", help="åªè¿è¡Œæ–‡æ¡£æ£€æŸ¥")
    parser.add_argument("--min-score", type=int, default=80, help="æœ€ä½è´¨é‡åˆ†æ•°")
    
    args = parser.parse_args()
    
    checker = QualityChecker()
    
    if args.all or not any([args.style, args.security, args.coverage, args.performance, args.docs]):
        score = checker.run_all_checks()
    else:
        if args.style:
            checker.results["checks"]["style"] = checker.check_python_style()
        if args.security:
            checker.results["checks"]["security"] = checker.check_security()
        if args.coverage:
            checker.results["checks"]["coverage"] = checker.check_test_coverage()
        if args.performance:
            checker.results["checks"]["performance"] = checker.check_performance()
        if args.docs:
            checker.results["checks"]["documentation"] = checker.check_documentation()
        
        score = checker.calculate_score()
        print(checker.generate_report())
    
    # æ ¹æ®åˆ†æ•°å†³å®šé€€å‡ºç 
    if score < args.min_score:
        logger.error(f"è´¨é‡åˆ†æ•° {score} ä½äºæœ€ä½è¦æ±‚ {args.min_score}")
        sys.exit(1)
    else:
        logger.info(f"è´¨é‡æ£€æŸ¥é€šè¿‡ï¼Œå¾—åˆ†: {score}")
        sys.exit(0)


if __name__ == "__main__":
    main() 